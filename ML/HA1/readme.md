# Результаты домашнего задания 1
## Часть 1. EDA
### Простейший EDA и обработка признаков
- Проверил данные на наличие дубликатов и удалил их.
- Построил базовый EDA на основе библиотеки ydata_profiling и сделал следующие выводы (цитата из ноутбука):

> Данный датасет имеет 5 текстовых признака, из которых 4 на самом деле не являются текстовыми. Этими признаками являются milage, engine, max_power и torque. Поэтому про них сейчас ничего, кроме того, что их надо будет обработать, сказать нечего.
> 
> Также в датасете есть 4 категориальных признака: fuel - тип топлива, используемый машиной, seller_type - продавец автомобиля, transmission - тип коробки передач, owner - сколько владельцев было у автомобиля.
> 
> Большинство машин является дизельными - 54.2%, далее идут бензиновые - 44.6%, самыми редкими идут машины на натуральном и сжижженом газе - 0.7% и 0.5% соответственно. Также 83.2% продавцов - это физические лица, дилерский центр - 13.8%, доверенный дилерский центр - 2.9%. Автоматическая коробка передач стоит всего на 12.9% автомобилей, остальные 87.1% - механические коробки передач. Распределение по количеству бывших владельцев автомобиля такое: один владелец - 65.5%; два - 25.6%; три - 6.8%; четыре и более - 2.1%; ни одного (тест драйв машина) - 0.1%.
> 
> Осталось разобрать 4 номинальных признака: year - год выпуска, selling_price - отпускная цена, km_driven - пробег в километрах, seats - количество сидений.
> 
> Квантили года выпуска такие: min - 1983, 5 процентиль - 2006, 25 процентиль - 2011, медиана - 2015, 75 процентиль - 2017, 95 процентиль - 2019, max - 2020. Средний год выпуска - 2013.8, стандартное отклонение - 4.05.
> 
> Квантили отпускной цены такие: min - 29999, 5 процентиль - 110000, 25 процентиль - 254999, медиана - 450000, 75 процентиль - 675000, 95 процентиль - 1925000, max - 10000000. Средняя отпускная цена - 639515.2, стандартное отклонение - 808941.91. Распределение похоже на логнормальное распределение.
> 
> Квантили пробега такие: min - 1, 5 процентиль - 9000, 25 процентиль - 35000, медиана - 60000, 75 процентиль - 97000, 95 процентиль - 150000, max - 2360457. Средний пробег - 69584.6, стандартное отклонение - 57724.
> 
> Квантили количества сидений такие: min - 2, 5 процентиль - 5, 25 процентиль - 5, медиана - 5, 75 процентиль - 5, 95 процентиль - 7, max - 14. Среднее количество сидений - 5.42, стандартное отклонение - 0.966.
- Заполнил пропуски медианными значениями (комментарий из ноутбука).
> Заполнение медианами могло сдвинуть распределение только в том случае, если значения nan появлялись только у некоторой определенной группы автомобилей. Если же такого не произошло, то в среднем у каждого автомобиля со значением nan должно было быть именно медианное значение, поэтому распределение изменилось только с точки зрения уменьшения дисперсии. Медиана измениться не могла.

- Преобразовал текстовые признаки с численными значениями в числовые с помощью регулярных выражений.
### Визуализации и корреляция
- В этой части изучил попарные зависимости с помощью sns.pairplot и различных корреляций.
- Вывод после изучения корреляции Пирсона для численных переменных:

> -   Какие 2 признака наименее скоррелированы между собой?
> 
 > Наименее скоррелированы между собой переменные year и engine.
 
> -   Между какими наблюдается довольно сильная положительная линейная зависимость?
> 
> Сильная положительная линейная связь наблюдается между парами (engine, max_power), (max_power, torque), (selling_price, max_power), (engine, seats).

> -   Правильно ли, опираясь на данные, утверждать, что чем меньше год, тем, скорее всего, больше километров проехала машина к дате продажи?
> 
> Не совсем правильно так утверждать. Мы можем сказать, что действительно год выпуска и пробег отрицательно скоррелированы между собой, но возможно этот эффект достигается за счёт зависимости между годом выпуска и другой переменной, которая в свою очередь влияет на пробег. Для того, чтобы выяснить это точнее, надо посмотреть на зависимость между годом и пробегом, зафиксировав другие переменные константами. Однако в первом приблежении, наблюдая только корреляцию, можно сказать, что это верно.
- Создал свою реализацию корреляции Спирмена, выводы по моей реализации из ноутбука:
> Две реализации корреляции Спирмена очень похожи, но есть небольшие отличия. Подозреваю, что эти различия происходят из-за того, что одинаковым значениям в Пандасе ранги присваиваются немного по-другому. В моей реализации используется метод rank(), который одинаковым значениям ставит ровно середину между двумя рангами (Условно, если сейчас сравниваются претенденты на 10 и 11 ранг, но значения у них совпадают, то обоим будет присвоен ранг 10.5)
- Реализовал Phi_k корреляцию, цитата из ноутбука:
> Phi_k корреляция показывает насколько хи-квадрат распределение, полученное из распределений по выборке с помощью двух наших переменных, отличается от распределения, которое было бы получено при условии независимости этих переменных. То есть phi_k корреляция по сути смотрит на значение ковариации полученное из матрицы дисперсий, которая получается при моделировании двумерного стандартного нормального распределения по нашему значению хи-квадрат для этих двух переменных.
> 
> Мы нашли, что по Phi_k корреляции больше всего друг с другом коррелируют следующие пары переменных: (selling_price, max_power), (max_power, torque), (torque, max_torque_rpm), (engine, max_power), (selling_price, torque), (fuel, max_torque_rpm), (mileage, max_power), (mileage, seats), (selling_price, mileage)
- Построил violin плоты для изучения выбросов данных.
## Часть 2. Модель только на вещественных признаках
- Реализовал r2 и adjusted r2 своими руками.
- Сделал нормировку вещественных признаков.
- Обучил линейную регрессию и линейную регрессию с L1 регуляризацией.
- Обучил GridSearch для линейной регрессии с L1 регуляризацией, а также GridSearch для ElasticNet'a. 
- Лучшая модель имела r2 = 0.6
## Часть 3. Добавляем категориальные фичи
- Преобразовал name в категориальную фичу, взяв только марку автомобиля (первое слово имени)
- Закодировал все категориальные фичи с помощью pd.get_dummies (OneHotEncoder)
- Ответы на вопросы из ноутбука: 
> - Как корректно работать с OHE преобразованием?
> 
> При работе с OHE для задачи регрессии мы должны сделать fit нашей OHE трансформации на обучающей выборке и применить её, выбрасывая одну категорию из каждого столбца. Далее мы делаем transform обучающей и тестовой выборки.
> 
> - Почему мы удаляем один столбец?
> 
> Потому что иначе наши столбцы, пораждаемые категорией, в которой не удалён один категориальный столбец, + интерсепт будут мультиколлинеарны. То есть при подсчёте матрица X^T*X, как и матрица X, будет иметь неполный ранг, что приведёт к тому, что она необратима и решений будет бесконечное множество и оно не сойдётся.
> 
> - Пусть из n признаков мы получили n−1 столбец, из которых k<n−1 оказались не важными по весам модели. Корректно ли их удалить?
> 
> Нет, некорректно, так как это один и тот же категориальный признак, поэтому оценивать важность весов надо также совместно.
- Обучили GridSearch для регрессии с L2 регуляризацией вместе с категориальными признаками, лучший r2 вырос до 0.775.
## Часть 4 - бонусная. Feature Engineering
- Решил сделать следующее:
> №1 Превратим нашу линейную регрессию в полиномиальную регрессию второй степени: добавим квадраты числовых признаков и interaction переменные между каждой парой числовых признаков
> 
> №2 Я немного опередил это задание и уже использовал марку автомобиля в предыдущей части. Теперь можем добавить ещё информации из name, оставив кроме марки машины ещё и модель.
> 
> №3 Давайте уберём выбросы из данных.
- После обучения с изменениями перечисленными выше r2 вырос до 0.934.
- По ощущениям самый большой прирост в качестве дало преобразование name в категориальную переменную и добавление нелинейных (полиномиальных второй степени) признаков.
## Часть 4. Бизнесовая
- Реализовал запрошенную метрику:
> Ожидаемо в последней модели самый большой показатель нашей бизнес метрики, также он ожидаемо растёт по ходу улучшения модели.
> 
> Business metric for model 1: 0.242 
> 
> Business metric for model 2: 0.242 
> 
> Business metric for model 3: 0.242 
> 
> Business metric for model 4: 0.242 
> 
> Business metric for model 5: 0.254 
> 
> Business metric for model 6: 0.294 
> 
> Business metric for model 7: 0.397

- Решил сделать следующую метрику: 
> Простой метрикой, которая наказывает за недопрогноз больше чем за перепрогноз, можно просто сделать долю автомобилей, которую мы недопрогнозируем больше чем на 10%. То есть какая доля машин нами обесценена больше чем на 10%.
> 
>Business metric for model 1: 0.358 
>
>Business metric for model 2: 0.358 
>
>Business metric for model 3: 0.358 
>
>Business metric for model 4: 0.35 
>
>Business metric for model 5: 0.346 
>
>Business metric for model 6: 0.348 
>
>Business metric for model 7: 0.296
>
- Опять же видим, что самая последняя модель справляется с бизнес задачей лучше всего (это метрика ошибок, поэтому меньше -> лучше)
## Часть 5. Реализация сервиса на FastAPI
- Реализовал сервис на FastAPI. 
- Так получилось, что я с самого начала не оборачивал модель в пайплайн, поэтому с входными данными пользователя приходится делать эти преобразования вручную ещё раз. Понимаю, что это не очень эффективно с точки зрения Production кода, но я впервые попытался написать API и хотя бы так у меня получилось. Зато он полностью рабочий! 
- Screenshot с реализацией метода post /predict_item
![enter image description here](https://raw.githubusercontent.com/DmitryKarasevAI/Homework/refs/heads/main/ML/HA1/scr1.png)
- Screenshot с реализацией метода post /predict_items
![enter image description here](https://raw.githubusercontent.com/DmitryKarasevAI/Homework/refs/heads/main/ML/HA1/scr2.png)
